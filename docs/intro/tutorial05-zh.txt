=====================================
编写你的第一个Django应用, 第5部分
=====================================

本教程上接 :doc:`教程 4 </intro/tutorial04-zh>`。我们已经开发了网页投票应用，现在
为它创建一些自动化测试。

自动化测试介绍
=============================

什么是自动化测试？
-------------------------

测试是检查代码操作的简单例行程序。

测试分为不同的级别。有些测试可能用于某个细节（*比如特定的模型方法是否返回预期的值？*），
而其他测试是检查软件的整体操作（*比如站点上一系列用户的输入是否产生期望的结果？*）。
这和 :doc:`教程 2 </intro/tutorial02-zh>` 中的测试是无异的，使用 :djadmin:`shell` 
来检查方法的行为，或者运行应用程序并输入数据来检查它的行为。

*自动化* 测试的不同之处在于测试工作是由系统帮您完成的。您创建一组测试，然后在对应用进行更改时，
您可以检查代码是否仍然按照原始的方式工作，而无需执行耗时的手动测试。

为什么需要自动化测试
----------------------------

那么为什么创建测试，为什么是现在？

你可能感觉学习 Python/Django 已经足够了，再去学习其他的东西也许需要付出巨大的努力而且没有必要，
毕竟我们的投票应用已经愉快地运行起来了。与其花时间去做自动化测试还不如改进现在的应用。如果
学习 Django 就是仅仅是为了创建一个小小投票应用，那么涉足自动化测试显然没有必要。但如果不是这样，
现在是一个很好的学习机会。

测试可以节约时间
~~~~~~~~~~~~~~~~~~~~~~~~

某种程度上，“检查能工作”似乎是种比较满意的测试结果。但在一些复杂的应用中，你会发现组件之间
存在各种各样复杂的交互关系。

这些组件有任何小的的更改都有可能会对应用程序的行为产生意想不到的后果。要检查它仍“能工作”，
可能意味着你需要使用二十种不同的测试数据来测试你的代码，而这仅仅是为了确保你没有做错某些事
—— 这不值得你花时间。

而自动化测试只需要数秒就可以完成以上的任务。如果出现了错误，还能够帮助找出引发这个异常行为的
代码。

有时候你可能会觉得编写测试程序相比起有价值的、创造性的编程工作显得单调乏味、无趣，
尤其是当你的代码工作正常时。

但是，比起用几个小时的时间来手动测试你的程序，或者试图找出代码中一个新生问题的原因，
编写自动化测试程序的性价比还是很高的。

测试可以发现并防止问题
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

将测试看做只是开发中消极的一面是错误的。

没有测试，应用程序的目的或预期行为可能是相当不透明的。即使这是你自己的代码，你也会发现
自己都不知道它在做什么。

测试可以改变这一情况；它们使你的代码内部变得明晰，当错误出现后，它们会明确地指出哪部分
代码出了问题 —— *甚至你自己都没意识到出现了问题*。

测试使您的代码更受欢迎
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

你可能已经创建了一个堪称辉煌的软件，但是你会发现许多其他的开发者会由于它缺少测试程序而
拒绝查看它；没有测试程序，他们不会信任它。Django最初的几个开发者之一 Jacob Kaplan-Moss 说过：“没有测试的代码是设计上的错误”。

你需要开始编写测试的另一个原因就是其他的开发者在他们认真研读你的代码前可能想要查看一下
它有没有测试。

测试有助于团队合作
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

之前的观点是从单个开发人员来维护一个程序这个方向来阐述的。复杂的应用将会被一个团队来维护。
测试能够减少同事在无意间破坏你的代码的情况（以及你在不知情的情况下破坏别人的代码的情况）。
如果你想作为Django程序员生活，你必须擅于编写测试！

基本的测试策略
========================

编写测试程序有很多种方法。

一些程序员遵循一种叫做“`测试驱动开发`_”的规则；他们在编写代码前会先写好测试。这看起来似乎
有点反人类，但实际上它与大多数人经常的做法很相似：先描述一个问题，然后编写代码来解决它。
测试驱动开发可以简单地在 Python 测试用例中将问题格式化。

很多时候，刚接触测试的人会先编写一些代码，再编写一些测试。事实上，更早编写一些测试会好一点，
但不管怎么说什么时候开始都不算晚。

有时候你很难决定从什么时候开始编写测试。如果你已经编写了数千行 Python 代码，挑选它们中的
一些来进行测试是不太容易的。这种情况下，在下次你对代码进行变更，添加一个新功能或者修复一个
bug 时，编写你的第一个测试，效果会非常好。下面，

让我们马上行动吧。

.. _测试驱动开发: https://en.wikipedia.org/wiki/Test-driven_development

编写我们的第一个测试
======================

发现bug
-----------------

很巧，在我们的 ``投票`` 应用中有一个小 bug 需要修改：当 ``Question`` 在最近的一天发布时,
``Question.was_published_recently()`` 返回True（这是正确的），然而当 ``Question`` 的
``pub_date`` 字段是未来的日期时也返回True（这是错误的）。

要检查该 bug 是否真的存在，使用 Admin 创建一个未来的日期，并使用 :djadmin:`shell` 检查::

    >>> import datetime
    >>> from django.utils import timezone
    >>> from polls.models import Question
    >>> # 创建一个pub_date在30天之后的Question实例
    >>> future_question = Question(pub_date=timezone.now() + datetime.timedelta(days=30))
    >>> # 它最近发布了吗？
    >>> future_question.was_published_recently()
    True

由于“将来”不等于“最近”，这显然是错的。

创建一个测试来暴露bug
-------------------------------

我们在 :djadmin:`shell` 中测试 bug 所做的也能在自动化测试中做到，让我们将之变为自动化测试吧。

通常，我们会把测试代码放在应用的 ``tests.py`` 文件中；测试系统将自动地从任何名字以
``test`` 开头的文件中查找测试。

将下面的代码放入 ``投票`` 应用的 ``tests.py`` 文件中：

.. snippet::
    :filename: polls/tests.py

    import datetime

    from django.utils import timezone
    from django.test import TestCase

    from .models import Question


    class QuestionModelTests(TestCase):

        def test_was_published_recently_with_future_question(self):
            """
            was_published_recently() returns False for questions whose pub_date
            is in the future.
            """
            time = timezone.now() + datetime.timedelta(days=30)
            future_question = Question(pub_date=time)
            self.assertIs(future_question.was_published_recently(), False)

我们在这里创建了一个 :class:`django.test.TestCase` 的子类，它的一个方法创建一个
``Question`` 实例， 其参数 ``pub_date`` 是未来的时间。最后我们检查
``was_published_recently()`` 的输出，它 *应该* 是 False。

Running tests
-------------

In the terminal, we can run our test::

    $ python manage.py test polls

and you'll see something like::

    Creating test database for alias 'default'...
    System check identified no issues (0 silenced).
    F
    ======================================================================
    FAIL: test_was_published_recently_with_future_question (polls.tests.QuestionModelTests)
    ----------------------------------------------------------------------
    Traceback (most recent call last):
      File "/path/to/mysite/polls/tests.py", line 16, in test_was_published_recently_with_future_question
        self.assertIs(future_question.was_published_recently(), False)
    AssertionError: True is not False

    ----------------------------------------------------------------------
    Ran 1 test in 0.001s

    FAILED (failures=1)
    Destroying test database for alias 'default'...

What happened is this:

* ``python manage.py test polls`` looked for tests in the ``polls`` application

* it found a subclass of the :class:`django.test.TestCase` class

* it created a special database for the purpose of testing

* it looked for test methods - ones whose names begin with ``test``

* in ``test_was_published_recently_with_future_question`` it created a ``Question``
  instance whose ``pub_date`` field is 30 days in the future

* ... and using the ``assertIs()`` method, it discovered that its
  ``was_published_recently()`` returns ``True``, though we wanted it to return
  ``False``

The test informs us which test failed and even the line on which the failure
occurred.

Fixing the bug
--------------

We already know what the problem is: ``Question.was_published_recently()`` should
return ``False`` if its ``pub_date`` is in the future. Amend the method in
``models.py``, so that it will only return ``True`` if the date is also in the
past:

.. snippet::
    :filename: polls/models.py

    def was_published_recently(self):
        now = timezone.now()
        return now - datetime.timedelta(days=1) <= self.pub_date <= now

and run the test again::

    Creating test database for alias 'default'...
    System check identified no issues (0 silenced).
    .
    ----------------------------------------------------------------------
    Ran 1 test in 0.001s

    OK
    Destroying test database for alias 'default'...

After identifying a bug, we wrote a test that exposes it and corrected the bug
in the code so our test passes.

Many other things might go wrong with our application in the future, but we can
be sure that we won't inadvertently reintroduce this bug, because simply
running the test will warn us immediately. We can consider this little portion
of the application pinned down safely forever.

More comprehensive tests
------------------------

While we're here, we can further pin down the ``was_published_recently()``
method; in fact, it would be positively embarrassing if in fixing one bug we had
introduced another.

Add two more test methods to the same class, to test the behavior of the method
more comprehensively:

.. snippet::
    :filename: polls/tests.py

    def test_was_published_recently_with_old_question(self):
        """
        was_published_recently() returns False for questions whose pub_date
        is older than 1 day.
        """
        time = timezone.now() - datetime.timedelta(days=1, seconds=1)
        old_question = Question(pub_date=time)
        self.assertIs(old_question.was_published_recently(), False)

    def test_was_published_recently_with_recent_question(self):
        """
        was_published_recently() returns True for questions whose pub_date
        is within the last day.
        """
        time = timezone.now() - datetime.timedelta(hours=23, minutes=59, seconds=59)
        recent_question = Question(pub_date=time)
        self.assertIs(recent_question.was_published_recently(), True)

And now we have three tests that confirm that ``Question.was_published_recently()``
returns sensible values for past, recent, and future questions.

Again, ``polls`` is a simple application, but however complex it grows in the
future and whatever other code it interacts with, we now have some guarantee
that the method we have written tests for will behave in expected ways.

Test a view
===========

The polls application is fairly undiscriminating: it will publish any question,
including ones whose ``pub_date`` field lies in the future. We should improve
this. Setting a ``pub_date`` in the future should mean that the Question is
published at that moment, but invisible until then.

A test for a view
-----------------

When we fixed the bug above, we wrote the test first and then the code to fix
it. In fact that was a simple example of test-driven development, but it
doesn't really matter in which order we do the work.

In our first test, we focused closely on the internal behavior of the code. For
this test, we want to check its behavior as it would be experienced by a user
through a web browser.

Before we try to fix anything, let's have a look at the tools at our disposal.

The Django test client
----------------------

Django provides a test :class:`~django.test.Client` to simulate a user
interacting with the code at the view level.  We can use it in ``tests.py``
or even in the :djadmin:`shell`.

We will start again with the :djadmin:`shell`, where we need to do a couple of
things that won't be necessary in ``tests.py``. The first is to set up the test
environment in the :djadmin:`shell`::

    >>> from django.test.utils import setup_test_environment
    >>> setup_test_environment()

:meth:`~django.test.utils.setup_test_environment` installs a template renderer
which will allow us to examine some additional attributes on responses such as
``response.context`` that otherwise wouldn't be available. Note that this
method *does not* setup a test database, so the following will be run against
the existing database and the output may differ slightly depending on what
questions you already created. You might get unexpected results if your
``TIME_ZONE`` in ``settings.py`` isn't correct. If you don't remember setting
it earlier, check it before continuing.

Next we need to import the test client class (later in ``tests.py`` we will use
the :class:`django.test.TestCase` class, which comes with its own client, so
this won't be required)::

    >>> from django.test import Client
    >>> # create an instance of the client for our use
    >>> client = Client()

With that ready, we can ask the client to do some work for us::

    >>> # get a response from '/'
    >>> response = client.get('/')
    Not Found: /
    >>> # we should expect a 404 from that address; if you instead see an
    >>> # "Invalid HTTP_HOST header" error and a 400 response, you probably
    >>> # omitted the setup_test_environment() call described earlier.
    >>> response.status_code
    404
    >>> # on the other hand we should expect to find something at '/polls/'
    >>> # we'll use 'reverse()' rather than a hardcoded URL
    >>> from django.urls import reverse
    >>> response = client.get(reverse('polls:index'))
    >>> response.status_code
    200
    >>> response.content
    b'\n    <ul>\n    \n        <li><a href="/polls/1/">What&#39;s up?</a></li>\n    \n    </ul>\n\n'
    >>> response.context['latest_question_list']
    <QuerySet [<Question: What's up?>]>

Improving our view
------------------

The list of polls shows polls that aren't published yet (i.e. those that have a
``pub_date`` in the future). Let's fix that.

In :doc:`Tutorial 4 </intro/tutorial04>` we introduced a class-based view,
based on :class:`~django.views.generic.list.ListView`:

.. snippet::
    :filename: polls/views.py

    class IndexView(generic.ListView):
        template_name = 'polls/index.html'
        context_object_name = 'latest_question_list'

        def get_queryset(self):
            """Return the last five published questions."""
            return Question.objects.order_by('-pub_date')[:5]

We need to amend the ``get_queryset()`` method and change it so that it also
checks the date by comparing it with ``timezone.now()``. First we need to add
an import:

.. snippet::
    :filename: polls/views.py

    from django.utils import timezone

and then we must amend the ``get_queryset`` method like so:

.. snippet::
    :filename: polls/views.py

    def get_queryset(self):
        """
        Return the last five published questions (not including those set to be
        published in the future).
        """
        return Question.objects.filter(
            pub_date__lte=timezone.now()
        ).order_by('-pub_date')[:5]

``Question.objects.filter(pub_date__lte=timezone.now())`` returns a queryset
containing ``Question``\s whose ``pub_date`` is less than or equal to - that
is, earlier than or equal to - ``timezone.now``.

Testing our new view
--------------------

Now you can satisfy yourself that this behaves as expected by firing up the
runserver, loading the site in your browser, creating ``Questions`` with dates
in the past and future, and checking that only those that have been published
are listed.  You don't want to have to do that *every single time you make any
change that might affect this* - so let's also create a test, based on our
:djadmin:`shell` session above.

Add the following to ``polls/tests.py``:

.. snippet::
    :filename: polls/tests.py

    from django.urls import reverse

and we'll create a shortcut function to create questions as well as a new test
class:

.. snippet::
    :filename: polls/tests.py

    def create_question(question_text, days):
        """
        Create a question with the given `question_text` and published the
        given number of `days` offset to now (negative for questions published
        in the past, positive for questions that have yet to be published).
        """
        time = timezone.now() + datetime.timedelta(days=days)
        return Question.objects.create(question_text=question_text, pub_date=time)


    class QuestionIndexViewTests(TestCase):
        def test_no_questions(self):
            """
            If no questions exist, an appropriate message is displayed.
            """
            response = self.client.get(reverse('polls:index'))
            self.assertEqual(response.status_code, 200)
            self.assertContains(response, "No polls are available.")
            self.assertQuerysetEqual(response.context['latest_question_list'], [])

        def test_past_question(self):
            """
            Questions with a pub_date in the past are displayed on the
            index page.
            """
            create_question(question_text="Past question.", days=-30)
            response = self.client.get(reverse('polls:index'))
            self.assertQuerysetEqual(
                response.context['latest_question_list'],
                ['<Question: Past question.>']
            )

        def test_future_question(self):
            """
            Questions with a pub_date in the future aren't displayed on
            the index page.
            """
            create_question(question_text="Future question.", days=30)
            response = self.client.get(reverse('polls:index'))
            self.assertContains(response, "No polls are available.")
            self.assertQuerysetEqual(response.context['latest_question_list'], [])

        def test_future_question_and_past_question(self):
            """
            Even if both past and future questions exist, only past questions
            are displayed.
            """
            create_question(question_text="Past question.", days=-30)
            create_question(question_text="Future question.", days=30)
            response = self.client.get(reverse('polls:index'))
            self.assertQuerysetEqual(
                response.context['latest_question_list'],
                ['<Question: Past question.>']
            )

        def test_two_past_questions(self):
            """
            The questions index page may display multiple questions.
            """
            create_question(question_text="Past question 1.", days=-30)
            create_question(question_text="Past question 2.", days=-5)
            response = self.client.get(reverse('polls:index'))
            self.assertQuerysetEqual(
                response.context['latest_question_list'],
                ['<Question: Past question 2.>', '<Question: Past question 1.>']
            )


Let's look at some of these more closely.

First is a question shortcut function, ``create_question``, to take some
repetition out of the process of creating questions.

``test_no_questions`` doesn't create any questions, but checks the message:
"No polls are available." and verifies the ``latest_question_list`` is empty.
Note that the :class:`django.test.TestCase` class provides some additional
assertion methods. In these examples, we use
:meth:`~django.test.SimpleTestCase.assertContains()` and
:meth:`~django.test.TransactionTestCase.assertQuerysetEqual()`.

In ``test_past_question``, we create a question and verify that it appears in
the list.

In ``test_future_question``, we create a question with a ``pub_date`` in the
future. The database is reset for each test method, so the first question is no
longer there, and so again the index shouldn't have any questions in it.

And so on. In effect, we are using the tests to tell a story of admin input
and user experience on the site, and checking that at every state and for every
new change in the state of the system, the expected results are published.

Testing the ``DetailView``
--------------------------

What we have works well; however, even though future questions don't appear in
the *index*, users can still reach them if they know or guess the right URL. So
we need to add a similar  constraint to ``DetailView``:

.. snippet::
    :filename: polls/views.py

    class DetailView(generic.DetailView):
        ...
        def get_queryset(self):
            """
            Excludes any questions that aren't published yet.
            """
            return Question.objects.filter(pub_date__lte=timezone.now())

And of course, we will add some tests, to check that a ``Question`` whose
``pub_date`` is in the past can be displayed, and that one with a ``pub_date``
in the future is not:

.. snippet::
    :filename: polls/tests.py

    class QuestionDetailViewTests(TestCase):
        def test_future_question(self):
            """
            The detail view of a question with a pub_date in the future
            returns a 404 not found.
            """
            future_question = create_question(question_text='Future question.', days=5)
            url = reverse('polls:detail', args=(future_question.id,))
            response = self.client.get(url)
            self.assertEqual(response.status_code, 404)

        def test_past_question(self):
            """
            The detail view of a question with a pub_date in the past
            displays the question's text.
            """
            past_question = create_question(question_text='Past Question.', days=-5)
            url = reverse('polls:detail', args=(past_question.id,))
            response = self.client.get(url)
            self.assertContains(response, past_question.question_text)

Ideas for more tests
--------------------

We ought to add a similar ``get_queryset`` method to ``ResultsView`` and
create a new test class for that view. It'll be very similar to what we have
just created; in fact there will be a lot of repetition.

We could also improve our application in other ways, adding tests along the
way. For example, it's silly that ``Questions`` can be published on the site
that have no ``Choices``. So, our views could check for this, and exclude such
``Questions``. Our tests would create a ``Question`` without ``Choices`` and
then test that it's not published, as well as create a similar ``Question``
*with* ``Choices``, and test that it *is* published.

Perhaps logged-in admin users should be allowed to see unpublished
``Questions``, but not ordinary visitors. Again: whatever needs to be added to
the software to accomplish this should be accompanied by a test, whether you
write the test first and then make the code pass the test, or work out the
logic in your code first and then write a test to prove it.

At a certain point you are bound to look at your tests and wonder whether your
code is suffering from test bloat, which brings us to:

When testing, more is better
============================

It might seem that our tests are growing out of control. At this rate there will
soon be more code in our tests than in our application, and the repetition
is unaesthetic, compared to the elegant conciseness of the rest of our code.

**It doesn't matter**. Let them grow. For the most part, you can write a test
once and then forget about it. It will continue performing its useful function
as you continue to develop your program.

Sometimes tests will need to be updated. Suppose that we amend our views so that
only ``Questions`` with ``Choices`` are published. In that case, many of our
existing tests will fail - *telling us exactly which tests need to be amended to
bring them up to date*, so to that extent tests help look after themselves.

At worst, as you continue developing, you might find that you have some tests
that are now redundant. Even that's not a problem; in testing redundancy is
a *good* thing.

As long as your tests are sensibly arranged, they won't become unmanageable.
Good rules-of-thumb include having:

* a separate ``TestClass`` for each model or view
* a separate test method for each set of conditions you want to test
* test method names that describe their function

Further testing
===============

This tutorial only introduces some of the basics of testing. There's a great
deal more you can do, and a number of very useful tools at your disposal to
achieve some very clever things.

For example, while our tests here have covered some of the internal logic of a
model and the way our views publish information, you can use an "in-browser"
framework such as Selenium_ to test the way your HTML actually renders in a
browser. These tools allow you to check not just the behavior of your Django
code, but also, for example, of your JavaScript. It's quite something to see
the tests launch a browser, and start interacting with your site, as if a human
being were driving it! Django includes :class:`~django.test.LiveServerTestCase`
to facilitate integration with tools like Selenium.

If you have a complex application, you may want to run tests automatically
with every commit for the purposes of `continuous integration`_, so that
quality control is itself - at least partially - automated.

A good way to spot untested parts of your application is to check code
coverage. This also helps identify fragile or even dead code. If you can't test
a piece of code, it usually means that code should be refactored or removed.
Coverage will help to identify dead code. See
:ref:`topics-testing-code-coverage` for details.

:doc:`Testing in Django </topics/testing/index>` has comprehensive
information about testing.

.. _Selenium: http://seleniumhq.org/
.. _continuous integration: https://en.wikipedia.org/wiki/Continuous_integration

What's next?
============

For full details on testing, see :doc:`Testing in Django
</topics/testing/index>`.

When you're comfortable with testing Django views, read
:doc:`part 6 of this tutorial</intro/tutorial06>` to learn about
static files management.
